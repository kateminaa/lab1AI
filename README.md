**Группа:** 425 Мина Е.А., Афанасьева К.А., Семенков Д., Егорова К.

**Вариант:**
- **Архитектура:** VGG-11
- **Оптимизатор:** Lars / Adam

---

## 1. Постановка задачи, Цель работы

**Постановка задачи:**  
Классификация изображений пород собак с использованием датасета Stanford Dogs Dataset. Необходимо реализовать и исследовать нейронную сеть VGG-11 и сравнить несколько стратегий обучения.

**Цели работы:**
1. Научиться загружать и предобрабатывать крупный датасет изображений (Stanford Dogs).
2. Реализовать архитектуру VGG-11 в PyTorch.
3. Провести два типа экспериментов: дообучение предобученной модели (fine-tuning) и обучение с нуля.
4. Сравнить методы оптимизации (Adam vs Lars) по метрикам Precision, Recall и F1-Score.
5. Подготовить отчёт и выложить исходный код и README на GitHub.

---

## 2. Теоретическая база

### 2.1 VGG-11 — краткое описание
VGG-11 — сверточная нейронная сеть с последовательностью 3×3 сверточных слоёв и блоков max-pooling, после чего идут полносвязные слои.  
- Глубина: 11 слоёв с обучаемыми параметрами.  
- Использует ReLU-активации и max-pooling.  
- Подходит для дообучения (transfer learning).

### 2.2 Fine-tuning (дообучение предобученной модели)
- Использование модели, предобученной на ImageNet.  
- Заморозка первых N слоёв (feature extractor) или полное дообучение (full fine-tuning).  
- Преимущество: быстрее сходимость и лучшая обобщающая способность при ограниченном числе данных.

### 2.3 Обучение с нуля (training from scratch)
- Инициализация весов случайно и обучение всей модели на целевом датасете.  
- Требует больше данных и эпох; выше риск переобучения.

### 2.4 Оптимизаторы
- **Adam:** адаптивный оптимизатор, быстрая сходимость.  
- **Lars:** масштабирует скорость обучения слоя пропорционально норме весов и градиента, полезен для крупных батчей.

### 2.5 Метрики качества
- **Precision:** доля верно предсказанных положительных примеров среди всех предсказанных положительных.  
- **Recall:** доля верно предсказанных положительных примеров среди всех реальных положительных.  
- **F1-Score:** гармоническое среднее Precision и Recall.

---

## 3. Экспериментальная часть

### 3.1 Датасет
**Stanford Dogs Dataset** — содержит изображения многих пород собак. Разбиение:  
- Train: 70%  
- Validation: 15%  
- Test: 15%  

### 3.2 Структура репозитория

Lab1
  data/ # датасет Stanford Dogs
  plots/ # графики 
  main.py # код обучения и оценки
  README.md


### 3.3 Результаты

**Таблица метрик:**

| Experiment           | Precision | Recall  | F1-Score |
|---------------------|-----------|---------|----------|
| Pretrained + LARS    | 0.0073    | 0.0114  | 0.0076   |
| Pretrained + Adam    | 0.7597    | 0.7552  | 0.7529   |
| Scratch + LARS       | 0.0008    | 0.0120  | 0.0013   |
| Scratch + Adam       | 0.0001    | 0.0083  | 0.0002   |

**Примеры графиков:**

Графики представленны в папке plots

---

## 4. Выводы

- Лучшие метрики достигнуты при Pretrained + Adam.  
- Дообучение предобученной модели значительно улучшает точность и F1-Score.  
- Lars плохо себя показал при выбранных гиперпараметрах и размере batch, лучше использовать Adam для небольших батчей.  
- Обучение с нуля показало крайне низкую точность из-за ограниченного объёма данных и малой эпохи обучения.

---

## 5. Использованные источники

- [PyTorch Documentation](https://pytorch.org/docs/stable/index.html)  
- Simonyan, K., & Zisserman, A. (2015). *Very Deep Convolutional Networks for Large-Scale Image Recognition.*  
- [Stanford Dogs Dataset](http://vision.stanford.edu/aditya86/ImageNetDogs/)
